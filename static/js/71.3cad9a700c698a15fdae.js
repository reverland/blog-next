webpackJsonp([71,178],{354:function(n,e){n.exports={rawContent:"\n\n简单展示和学习，清晰为主，不考虑效率。\n\n本文简单讨论支持GET/CONNECT方法的http代理。这两种可能是最常用的方法。GET请求用于大多数http请求，CONNECT请求负责处理https。\n\n为了更加明晰，也没有使用requests或者httplib等其它模块，没有使用SocketServer和它的子类，因为我个人觉得从socket开始能有个更加清晰的理解。\n\n看着玩吧。\n\n如果真的要用一个Proxy，我会直接使用pytho中的twisted或者BaseHTTPServer，或者基于nodejs的。它们有着更好的设计和更高层次的抽象，当然，更全面的特性和更稳定、更高的性能。文末将给出相关资料与实现。\n\n请准备好一台linux系统，安装好netcat, openssl和python解释器。目前我用的还是2.7。\n\n## 基本原理\n\n### 客户服务器模型\n\n首要问题是：客户服务器之间如何通信。简单说来就是客户端发送请求，告诉服务器我要什么东西，服务器则告诉客户端想要的东西或者告诉客户端找不到。\n\n首先，客户端比如你的浏览器要找到服务器，通常的做法是在浏览器地址栏输入你想寻找的服务器。至于怎么寻找，如何最后在你的客户端和服务器间建立连接这点不细说。总之最后的结果是，两者之间建立了一条可以互相通话的专有线路，就像两个打电话的人一样，电话已经接通。\n\n接着，你的浏览器说，我想要什么什么东西，有什么什么要求。电话另一头的服务器听到后就回复它有没有什么东西，如果有返回个什么样的东西，然后把东西传给你的浏览器。\n\n接受到从服务器传来的数据后，浏览器把一堆你看不懂的东西绘制到屏幕上，绘声绘色地显示给你。\n\n就这么简单。详情请参考RFC 2616，这是第一手最好的资料。\n\n下面让我么实际看看他们都怎么通话的\n\n我们先看看不用代理时，浏览器向服务器发送了些什么。监听本地8888端口\n\n     ~ ⮀ nc -lvp 8888\n    listening on [any] 8888 ...\n    connect to [127.0.0.1] from localhost [127.0.0.1] 56499\n    GET /index.html?haha=1&papa=2 HTTP/1.1 Host: localhost:8888 User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Firefox/24.0\n    Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\n    Accept-Language: en-US,en;q=0.5\n    Accept-Encoding: gzip, deflate\n    Cookie:  __utma=XXXXXXXXXXXXXXXXXXXXXXXXXx; __utmz=111x7x2x1.13x86x7x41.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none)\n    Connection: keep-alive\n                         \n\n忽略无关紧要的细节，这就是传说中的HTTP头。注意，最后还得有个空行表示我说完了。它告诉服务器以下一些信息：\n\n- 浏览器想做什么(`GET`)\n- 想要什么(`index.html?haha=1&papa=2`)\n- 说的什么版本的什么话(`HTTP/1.1`)\n- 要的东西在哪里(`Host`)\n- 浏览器的一些特征(`User-Agent:`)\n- 浏览器接收什么样的东西(`Accept`)\n- 浏览器可以接受什么样的人类语言(`Accept-Language`)\n- 浏览器能处理的压缩或编码方式(`Accept-Encoding`)\n- 其它信息(标识浏览器身份的`Cookie`和在通话完成后是否把电话挂掉的信息`Connection`)\n\n对于特定版本的HTTP协议1.1，除了前两行是必要的其它都是可选的。\n\n我们再看看服务器返回的信息是啥样的。\n\n     ~ ⮀ nc baidu.com 80\n    GET / HTTP/1.1\n    Host: baidu.com\n    \n    HTTP/1.1 200 OK\n    Date: Mon, 03 Feb 2014 07:37:46 GMT\n    Server: Apache\n    Cache-Control: max-age=86400\n    Expires: Tue, 04 Feb 2014 07:37:46 GMT\n    Last-Modified: Tue, 12 Jan 2010 13:48:00 GMT\n    ETag: \"51-4b4c7d90\"\n    Accept-Ranges: bytes\n    Content-Length: 81\n    Connection: Keep-Alive\n    Content-Type: text/html\n    \n    <html>\n    <meta http-equiv=\"refresh\" content=\"0;url=http://www.baidu.com/\">\n    </html>\n\n服务器返回了这些信息：\n\n- 服务器端用什么版本的什么话通信(`HTTP/1.1`)\n- 浏览器请求的资源是否可获得(`200 OK`)\n- 还有其它细节用来表示时间，它的情况，浏览器应该怎么做，传送的消息是什么等等。\n\n这就是传说中的HTTP响应头。一个空行之后是实际传送的数据。嗯，这里就是浏览器喜欢的html文本文件。浏览器接收后会将其解析渲染或执行对应操作。\n\n嗯基本原理就是这样。\n\n## 连接的建立\n\n当我们谈互联网时，不得不说说什么是socket。\n\n当然，还得知道互联网的分层架构。\n\n然而暂时不要管什么是socket，反正它就存在在那里，整个互联网建立在socket通信之上，包括Unix系统的内部通信。\n\n可以把它设想成一个通信管道或线路的入口。如何使用它呢？拿python示例：\n\n    import socket\n    soc = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\n我们先导入socket模块，然后建立了一种指定类型的socket，嗯，这里是支持IPv4上TCP连接的socket。\n\n一个服务器应该这样，要先绑定，然后监听：\n\n    soc.bind(\"\", 8888)\n    new_soc, address = soc.accept()\n    new_soc.recv(1024)\n\n以上将socket绑定到本地(`\"\"`)的8888端口。这样，所有连接到本机8888端口的连接实际上都是通过这个socket连接了。\n\n接着，开始监听，一旦有客户端连接本机8888端口，就返回它的地址(address)和一个新的socket。注意，服务器端socket并不进行通信，只监听连接并生成一个新的用来连接的socket。然后，可以通过这个新的socket和客户端通信。\n\n客户端则比较简单：\n\n    soc.connect(localhost, 8888)\n    soc.send(\"GET / HTTP/1.1\\r\\nHost: baidu.com\\r\\n\\r\\n\")\n\n连接某个机器的某个端口后则可以通过socket进行通信\n\n### 代理服务器\n\n代理服务器，是服务器和客户端之间一个中间站。将客户端发送的请求转发给服务器，将服务器的响应转发给客户端。\n\n当我们说到代理服务器，首先它是一个服务器。\n\n有了上面的基础可以写出以下代码，更多细节参考Python的socket文档：\n\n    import socket\n    soc.bind(\"\", 8888)\n    while True:\n        # 监听接入的连接\n        new_soc, address = soc.accept()\n        # 从socket读取数据\n        data = new_soc.recv(1024)\n        # 向socket发送数据\n        new_soc.send(data)\n\n其次它是一个客户端，它要向服务器请求数据。\n\n其次它是个web服务器，尽管它大部分数据只需要转发。但它应该能处理HTTP协议，只是不必什么都处理。下面将展示有哪些地方在转发时必须处理。\n\n### 火狐在使用代理时的HTTP头\n\n与不使用代理时有什么不同呢？\n\n    ~ ⮀ nc -lvp 8000\n    listening on [any] 8000 ...\n    connect to [127.0.0.1] from localhost [127.0.0.1] 60601\n    GET http://baidu.com/ HTTP/1.1\n    Host: baidu.com\n    User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Firefox/24.0\n    Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\n    Accept-Language: en-US,en;q=0.5\n    Accept-Encoding: gzip, deflate\n    Cookie: BAIDUID=×××××××××××××××:FG=1; BDUSS=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX; bid_1=XXXXXXXXXXXXXXXXXXX; MCITY=-XXXXXXXXX%3A\n    Connection: keep-alive\n\n注意没，GET后面不是请求的文件的路径，而是整个URI。那么我们的代理服务器得把浏览器的请求改成路径再转发。\n\n其次，我们不希望再转发给baidu.com的服务器之后服务器不断开连接而一直保持，我们希望它赶紧断开连接好让我们能干点其它事。\n\n    Connection: close\n\n综上，一个简单的能处理GET请求的代理服务器应该能做到：\n\n- 将浏览器请求的第一行中完整的URL(http://baidu.com/)替换成路径('/')，通常情况下，没有指定资源文件的情况下默认是`/index.html`。\n- 将HTTP头中的Connection设置为close。\n\n基本原理就是这样，嗯，多简单。\n\n## 实现代(和谐)理\n\n我们可以先写点什么验证我们的想法，\n\n    #!/usr/bin/env python\n    # -*- coding: utf-8 -*-\n    \n    import socket\n    import urlparse\n    \n    HOST = ''                 # Symbolic name meaning all available interfaces\n    PORT = 8000              # Arbitrary non-privileged port\n    \n    \n    def server(host, port):\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        s.bind((host, port))\n        s.listen(500)\n        print \"Serving at %s\" % PORT\n        while 1:\n            try:\n                conn, addr = s.accept()\n                handle_connection(conn)\n            except KeyboardInterrupt:\n                print \"Bye...\"\n                break\n    \n    \n    def getline(conn):\n        line = ''\n        while 1:\n            buf = conn.recv(1)\n            if buf == '\\r':\n                line += buf\n                buf = conn.recv(1)\n                if buf == '\\n':\n                    line += buf\n                    return line\n            # elif buf == '':\n            #     return\n            else:\n                line += buf\n    \n    \n    def get_header(conn):\n        '''\n        不包括\\r\\n\n        '''\n        headers = ''\n        while 1:\n            line = getline(conn)\n            if line is None:\n                break\n            if line == '\\r\\n':\n                break\n            else:\n                headers += line\n        return headers\n    \n    \n    def parse_header(raw_headers):\n        request_lines = raw_headers.split('\\r\\n')\n        first_line = request_lines[0].split(' ')\n        method = first_line[0]\n        full_path = first_line[1]\n        version = first_line[2]\n        print \"%s %s\" % (method, full_path)\n        (scm, netloc, path, params, query, fragment) \\\n            = urlparse.urlparse(full_path, 'http')\n        # 如果url中有‘：’就指定端口，没有则为默认80端口\n        i = netloc.find(':')\n        if i >= 0:\n            address = netloc[:i], int(netloc[i + 1:])\n        else:\n            address = netloc, 80\n        return method, version, scm, address, path, params, query, fragment\n    \n    \n    def handle_connection(conn):\n        # 从socket读取头\n        req_headers = get_header(conn)\n        # 更改HTTP头\n        ## 要没有HTTP头的话。。。\n        if req_headers is None:\n            return\n        method, version, scm, address, path, params, query, fragment = \\\n            parse_header(req_headers)\n        path = urlparse.urlunparse((\"\", \"\", path, params, query, \"\"))\n        req_headers = \" \".join([method, path, version]) + \"\\r\\n\" +\\\n            \"\\r\\n\".join(req_headers.split('\\r\\n')[1:])\n        # 建立socket用以连接URL指定的机器\n        soc = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        # soc.settimeout(1)\n        # 尝试连接\n        try:\n            soc.connect(address)\n        except socket.error, arg:\n            conn.sendall(\"HTTP/1.1\" + str(arg[0]) + \" Fail\\r\\n\\r\\n\")\n            conn.close()\n            soc.close()\n        else:  # 若连接成功\n            # 把HTTP头中连接设置为中断\n            # 如果不想让火狐卡在那里不继续加载的话\n            if req_headers.find('Connection') >= 0:\n                req_headers = req_headers.replace('keep-alive', 'close')\n            else:\n                req_headers += req_headers + 'Connection: close\\r\\n'\n            # 发送形如`GET path/params/query HTTP/1.1`\n            # 结束HTTP头\n            req_headers += '\\r\\n'\n            soc.sendall(req_headers)\n            # 发送完毕, 接下来从soc读取服务器的回复\n            # 建立个缓冲区\n            data = ''\n            while 1:\n                try:\n                    buf = soc.recv(8129)\n                    data += buf\n                except:\n                    buf = None\n                finally:\n                    if not buf:\n                        soc.close()\n                        break\n            # 转发给客户端\n            conn.sendall(data)\n            conn.close()\n    if __name__ == '__main__':\n        server(HOST, PORT)\n\n运行它并且将浏览器设置为使用该代理：\n\n    python socket-proxy.py\n\n在本地建立一个web服务器实验：\n\n    ~/Work/project/proxy/base_python ⮀ python -m SimpleHTTPServer 8888 \n\n在浏览器中访问`http://localhost:8888`,成功列出当前目录。\n\n你可以直接访问任何网站看看。渐渐会发现，我们的代理服务器虽然运行基本良好，一次却只能接受一个请求？非常低效。程序经常会阻塞在socket的读写上。\n\n目前来说，提高效率有三种途径：\n\n- 异步I/O\n- 线程\n- 进程\n\n然而，本文暂不讨论如何提高效率。也许下回或某天会专门说说。我们接着再谈谈CONNECT代理实现原理。\n\n## 可进行https连接的http代理\n\nhttps是建立在SSL/TLS上的安全连接，不要在意它是什么，我们只谈及它做什么。\n\n通过SSL/TLS建立点与点之间的连接不被窃听。我们要为https连接代理的话，代理服务器就只能帮助客户端和服务器建立一条安全的加密通道，然后仅仅将数据中转。由于是加密的数据流，代理服务器并不能理解是什么，只看到一堆加密后的字符。\n\nHTTP协议规定了一种CONNECT方法，用来向服务器申请这种中转。具体过程我们可以自己试着访问`https://google.com`看看，首先将浏览器代理设置为本地8000端口:\n\n    ~ ⮀ nc -lvp 8000\n    listening on [any] 8000 ...\n    connect to [127.0.0.1] from localhost [127.0.0.1] 43263\n    CONNECT google.com:443 HTTP/1.1\n    User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Firefox/24.0\n    Proxy-Connection: keep-alive\n    Connection: keep-alive\n    Host: google.com\n    \n    200 OK\n    ��R����^��4G��>�<�N�R���D1kVg|X�lH��\n    ���98���5�      ���ED32��\n    ���                      ���A/��\n    -\n    google.com\n    ▒\n     #3t\n\n我们可以看到\n\n- 客户端向代理服务器申请代理(`CONNECT google.com:443 HTTP/1.1`)\n- 代理服务器向客户端应答表示可以代理(`200 OK`)\n- 客户端开始发送数据，准备建立加密信道\n\n剩下的工作应该由代理服务器继续。\n\n- 代理服务器建立一条与服务器的socket连接，\n- 代理服务器在服务器和客户端之间转发数据。\n\n我们简单更改之前的简单脚本使之支持CONNECT（毫无设计的脚本风格写法……见笑）：\n\n    def handle_connection(conn):\n        # 从socket读取头\n        req_headers = get_header(conn)\n        # 更改HTTP头\n        ## 要没有HTTP头的话。。。\n        if req_headers is None:\n            return\n        method, version, scm, address, path, params, query, fragment = \\\n            parse_header(req_headers)\n        if method == 'GET':\n            do_GET(conn,\n                   req_headers,\n                   address,\n                   path,\n                   params,\n                   query,\n                   method,\n                   version)\n        elif method == 'CONNECT':\n            # 注意\n            address = (path.split(':')[0], int(path.split(':')[1]))\n            do_CONNECT(conn,\n                       req_headers,\n                       address)\n    \n    \n    def do_CONNECT(conn, req_headers, address):\n        # 建立socket用以连接URL指定的机器\n        soc = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        # soc.settimeout(4)\n        # 尝试连接\n        try:\n            soc.connect(address)\n        except socket.error, arg:\n            conn.sendall(\"/1.1\" + str(arg[0]) + \" Fail\\r\\n\\r\\n\")\n            conn.close()\n            soc.close()\n        else:  # 若连接成功\n            conn.sendall('HTTP/1.1 200 Connection established\\r\\n\\r\\n')\n            # 数据缓冲区\n            # 读取浏览器给出的消息\n            try:\n                while True:\n                    # 从客户端读取数据，并转发给conn\n                    data = conn.recv(99999)\n                    soc.sendall(data)\n                    # 从服务器读取回复，转发回客户端\n                    data = soc.recv(999999)\n                    conn.sendall(data)\n            except:\n                conn.close()\n                soc.close()\n    \n    \n    def do_GET(conn, req_headers, address, path, params, query, method, version):\n        path = urlparse.urlunparse((\"\", \"\", path, params, query, \"\"))\n        req_headers = \" \".join([method, path, version]) + \"\\r\\n\" +\\\n            \"\\r\\n\".join(req_headers.split('\\r\\n')[1:])\n        # 建立socket用以连接URL指定的机器\n        soc = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        # soc.settimeout(1)\n        # 尝试连接\n        try:\n            soc.connect(address)\n        except socket.error, arg:\n            conn.sendall(\"HTTP/1.1\" + str(arg[0]) + \" Fail\\r\\n\\r\\n\")\n            conn.close()\n            soc.close()\n        else:  # 若连接成功\n            # 把HTTP头中连接设置为中断\n            # 如果不想让火狐卡在那里不继续加载的话\n            if req_headers.find('Connection') >= 0:\n                req_headers = req_headers.replace('keep-alive', 'close')\n            else:\n                req_headers += req_headers + 'Connection: close\\r\\n'\n            # 发送形如`GET path/params/query HTTP/1.1`\n            # 结束HTTP头\n            req_headers += '\\r\\n'\n            soc.sendall(req_headers)\n            # 发送完毕, 接下来从soc读取服务器的回复\n            # 建立个缓冲区\n            data = ''\n            while 1:\n                try:\n                    buf = soc.recv(8129)\n                    data += buf\n                except:\n                    buf = None\n                finally:\n                    if not buf:\n                        soc.close()\n                        break\n            # 转发给客户端\n            conn.sendall(data)\n            conn.close()\n\n在终端运行代理：\n\n    python socket-proxy.py\n\n紧接着我们用openssl搭建一个简单的测试用https服务器。\n\n首先生成私钥：\n\n     ~/Work/project/proxy/base_python ⮀ openssl genrsa -out privkey.pem 1024    \n    Generating RSA private key, 1024 bit long modulus\n    ..++++++\n    ...............................................++++++\n    e is 65537 (0x10001)\n\n生成一个未签名的证书：\n\n     ~/Work/project/proxy/base_python ⮀ openssl req -new -x509 -key privkey.pem -out cert.pem\n    You are about to be asked to enter information that will be incorporated\n    into your certificate request.\n    What you are about to enter is what is called a Distinguished Name or a DN.\n    There are quite a few fields but you can leave some blank\n    For some fields there will be a default value,\n    If you enter '.', the field will be left blank.\n    -----\n    Country Name (2 letter code) [AU]:\n    State or Province Name (full name) [Some-State]:\n    Locality Name (eg, city) []:\n    Organization Name (eg, company) [Internet Widgits Pty Ltd]:\n    Organizational Unit Name (eg, section) []:\n    Common Name (e.g. server FQDN or YOUR name) []:\n    Email Address []:\n\n把私钥和证书合在一起生成服务器能使用的文件：\n\n     ~/Work/project/proxy/base_python ⮀ cat privkey.pem cert.pem > server.pem\n\n建立测试https服务器\n\n     ~/Work/project/proxy/base_python ⮀ openssl s_server -accept 8888 -cert server.pem -www\n    Using default temp DH parameters\n    ACCEPT\n    ACCEPT\n    ACCEPT\n\n使用浏览器先直接访问，再试着用自己写的代理服务器访问下。bingo！It really works！\n\n## Last but not least\n\n从头到尾，好像两句话就能讲清楚的原理竟然花了这么多笔墨去解释。\n\n总之，如果想真的让代理“能用”，使用线程或异步I/O来实现是必然的。在以后的某天，大概会详细对各种从select到asyncio每个层面的异步来做个走马观花的简介。\n\n## 参考资料\n\n主要参考资料：\n\n- [socket — Low-level networking interface](http://docs.python.org/2/library/socket.html)\n- [Simple SSL cert HOWTO](http://www.devsec.org/info/ssl-cert.html)\n- [RFC2616 Hypertext Transfer Protocol -- HTTP/1.1](https://tools.ietf.org/html/rfc2616)\n- [RFC2817 Upgrading to TLS Within HTTP/1.1](http://www.ietf.org/rfc/rfc2817.txt)\n- [When should one use CONNECT and GET HTTP methods at HTTP Proxy Server?](http://stackoverflow.com/questions/11697943/when-should-one-use-connect-and-get-http-methods-at-http-proxy-server)\n- [Openssl Documentation:s_server(1)](http://www.openssl.org/docs/apps/s_server.html)\n- [HTTP Tunnel](http://en.wikipedia.org/wiki/HTTP_tunnel)\n- [HTTPS](http://en.wikipedia.org/wiki/HTTP_Secure)\n- [Unable to load certificate in openssl](http://serverfault.com/questions/473155/unable-to-load-certificate-in-openssl)\n\n如果你想学习异步：\n\n- [The new python asyncio aka tulip](http://haypo-notes.readthedocs.org/asyncio.html)\n- [How To Use Linux epoll with Python](http://scotdoyle.com/python-epoll-howto.html)\n- [The C10K problem](http://www.kegel.com/c10k.html)\n\n呵呵，就这些吧。竟然死机了，还连死两次，已经好久不知道什么叫死机了，白添加半天链接vim自动保存一恢复反而恢复没了。\n\n最近vim倒挺顺，也不卡也不闹，本来第一次司机恢复下恢复写的内容，结果尼玛还没保存又死机死机死机死机了。firefox不知道怎么回事就卡住然后就鼠标能动键盘都卡住。还有我打字时fcitx这么卡你爸妈知道么，没以前感觉智能无所谓，要不要敲个字等一秒再出来！！！\n\n忽然顺了……我擦……\n\n## OT\n\n- [Twisted简介和异步编程入门](https://github.com/luocheng/twisted-intro-cn)\n- 哈哈，成功完成python2 koans\n",metaData:{layout:"post",title:"用python写一个http代(和谐)理",excerpt:"一个一步步写http代和谐理教程",category:"python",tags:["python"],disqus:!0}}}});
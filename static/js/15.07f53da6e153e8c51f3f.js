webpackJsonp([15,170],{394:function(n,e){n.exports={rawContent:'\n\n## 每一颗眼泪，是一万道光：迎新系统学生信息爬取\n\n> You don\'t get over the fear. You run towards it, with your knees buckling.\n> \n> ---Amin Ariana, Technical Founder, hacker and advisor at several ventures\n\n有多少次，希望那短暂平凡的一刻又一刻定格到永恒。\n\n简简单单就是幸福\n\n忘乎所有只有热爱\n\n--------------------\n\n去年8月，来跪邮写得第一个程序。在学十还略显空荡的房间，空荡荡的桌面，床上没有被子只有个睡袋，惨白惨白的灯光和兴奋的新同学们。\n\n这次，依然是selenium专场。让程序操作浏览器。\n\n首先，依然是研究整个流程。\n \n打开 http://welcome.bupt.edu.cn\n\n看看怎么登录\n\n![](/images/spider/yingxin.png)\n\n一切显而易见，输入用户名密码，点击登录按钮。\n\n进入界面\n\n![](/images/spider/yingxin1.png)\n\n这时候看到有个选框，发现可以选择研究生或者本科生。在这里我不讨论这个问题，留作读者自己思考。\n\n我们随便翻翻看看\n\n注意到左下角有几个页码，左边还有个`3136/210`之类的东西。\n\n大概研究下猜想，3136是学生总数，210是总页数。\n\n同时注意到页码是一次显示5页，通过点击`>`翻入下个5页。\n\n![](/images/spider/yingxin2.png)\n\n为了得到我们要翻多少页，需要提取出210这个数。我们已经讲过如何用xpath来索引到对应的元素。\n\n![](/images/spider/yingxin3.png)\n\n紧接着，抓取，点击下一页，每翻五页，点击`>`，然后继续重复以上步骤。\n\n直到把210页全翻完。\n\n我们要提取的信息在class`porlet-table`中\n\n![](/images/spider/yingxin4.png)\n\n接着，一切都显而易见了，用selenium自动化这个步骤。\n\n我是直接在ipython中一点点试验这个过程，最后把历史记录摘录出来写成程序，最后在ipython中打开pdb自动捕捉异常的功能或者设置断点来运行调试。\n\n当然，也许你使用自己的方式。\n\n```python\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n\nfrom selenium import webdriver\n#from selenium.webdriver.common.keys import Keys\nimport time\nimport random\n\n__author__ = \'Reverland\'\n\n"""\nYou know what it is...\nWith NO warranty.\nAt your OWN risk.\n\nA quick and dirty spider implemented with selenium webdriver\nto dump the students\' dorm data\n\n条码号  姓名    院系    专业    学号    班级    宿舍校区    宿舍区  宿舍楼\n宿舍房号    床号    入住情况\n"""\n\ndriver = webdriver.Firefox()\ndriver.get("http://welcome.bupt.edu.cn")\nusername = driver.find_element_by_id("username")\npassword = driver.find_element_by_id("password")\nusername.send_keys("2xxxxxx")\npassword.send_keys("xxxxx")\nsubmit = driver.find_element_by_name("submit")\nsubmit.click()\n\ntime.sleep(2)\n\n# login success\n# y\np = 1\nxpath_p_last = \'//div[@class="pagination-info clearFix"]/span\'\nn_pages = driver.find_element_by_xpath(xpath_p_last)\np_last = int(n_pages.text.split(\'/\')[1])\nn_student = int(n_pages.text.split(\'/\')[0])\nprint "Number of Students Found: ", n_student\nwhile (p <= p_last):\n    time.sleep(random.randint(3, 5))\n    table = driver.find_element_by_class_name("portlet-table")\n    # remove headers\n    text = table.text[45::] + \'\\n\'\n    print text\n    with open("bupt_students_yan.txt", \'a\') as f:\n        f.write(text.encode(\'utf-8\'))\n    p += 1\n    if p > p_last:\n        print "finished"\n        break\n    if p % 5 == 1:\n        driver.find_element_by_link_text(">").click()\n    else:\n        driver.find_element_by_link_text(str(p)).click()\n\n# b\noption = driver.find_element_by_xpath(\'//select/option[@value="serieN10B"]\')\noption.click()\np = 1\nxpath_p_last = \'//div[@class="pagination-info clearFix"]/span\'\nn_pages = driver.find_element_by_xpath(xpath_p_last)\np_last = int(n_pages.text.split(\'/\')[1])\nn_student = int(n_pages.text.split(\'/\')[0])\nprint "Number of Students Found: ", n_student\nwhile (p <= p_last):\n    time.sleep(random.randint(3, 5))\n    table = driver.find_element_by_class_name("portlet-table")\n    # remove headers\n    text = table.text[45::] + \'\\n\'\n    print text\n    with open("bupt_students_ben.txt", \'a\') as f:\n        f.write(text.encode(\'utf-8\'))\n    p += 1\n    if p > p_last:\n        print "finished"\n        break\n    if p % 5 == 1:\n        driver.find_element_by_link_text(">").click()\n    else:\n        driver.find_element_by_link_text(str(p)).click()\n```\n\nHappy hacking~\n\n![](/images/spider/yingxin6.png)\n',metaData:{layout:"post",title:"Python Spider: 迎新系统学生信息爬取",excerpt:"速写爬虫的一些经历",category:"python",tags:["python","spider"],disqus:!0}}}});
//# sourceMappingURL=15.07f53da6e153e8c51f3f.js.map
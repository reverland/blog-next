webpackJsonp([40,194],{586:function(n,e){n.exports={rawContent:"\n\n## 超星数字图书馆(北邮镜像): 在线阅读书籍爬取转换(selenium) \n\n> 我忧心忡忡地看待未来，但仍满怀美好的希望。\n> \n> —— Albert Schweitzer\n\n这次推荐selenium，自从有了selenium，爬虫从来没有这么简单过。\n\n------\n\n几天前，一个工作的同学想让我帮他借一本书《聚酰亚胺新型材料》，他工作上需要看这本书的一些内容，但是这本书已经绝版，网上也没有出售。\n\n于是我帮他搜索了下，图书馆里没有这本书。忽然想起来我邮还买了很多电子资源。\n\n于是从图书馆主页选择`电子图书`->`超星数字电子图书数据`，进入如下页面。\n\n![](/images/spider/chaoxing.png)\n\n搜索了下这本书，找到了一本。\n\n![](/images/spider/chaoxing1.png)\n\n太棒了，下载下来……额……下载需要阅读器……\n\n![](/images/spider/chaoxing2.png)\n\n对一个伪geek最讨厌的事情之一就是，某个牛比的企业倚杖其资源绑架用户安装所谓的客户端。比如讨厌的腾讯和讨厌的淘宝。\n\n自然也不会下载什么阅读器，但是，既然可以在线看，那么就可以下载下来。实在在不行我浏览器截图行么。\n\nselenium让一切成为可能(包括截图)。\n\n让我们在线阅读：\n\n![](/images/spider/chaoxing3.png)\n\n在线阅读提供了一些功能，包括索引、目录和文字提取，悲剧的是下载下来之后转成的pdf可没有这么多道道。虽然，如果肯花时间解决这些都不是问题……但是，我们又不是想pirate电子书……\n\n对页面按右键发现这是个图片！接着观察对应的源码发现，是一个input标签，仔细观察这个input标签你可以看到很多属性，比如比较重要的class、scr、src、jpgname。\n\n仔细多观察一个，你会发现，class是Jimg的似乎都是书页内容、jpgname属性是页码、scr和src好像都是书页图片地址。\n\n![](/images/spider/chaoxing4.png)\n\n你可以试试。说服自己那些就是书页图片地址\n\n![](/images/spider/chaoxing6.png)\n\n多看几个发现下面的页面其实src属性都是假的，猜测是书页滚动到某个页面，通过js动态修改src来实现实时加载而不是一下全加载。\n\n![](/images/spider/chaoxing5.png)\n\n那么，我们抓取当前网页阅读页面所有class属性是`Jimg`的input标签的`scr`标签，就可以获取所有书页的图像了。\n\n接下来，看看selenium是多么丧心病狂……\n\n我们把以上所有从搜索到在线阅读的过程自动化……\n\n```python\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport sys\nimport time\nimport os\nimport imghdr\nimport urllib\nimport urllib2\nfrom selenium import webdriver\n\n# bookname = u'聚酰亚胺新型材料'\ntry:\n    bookname = unicode(sys.argv[1], 'utf-8')\nexcept:\n    print \"[Usage:] chaoxing.py bookname\"\n    sys.exit(1)\ndriver = webdriver.Firefox()\n\n# 首先搜索\n\nurl = 'http://sslibbook2.sslibrary.com'\n\ndriver.get(url)\ntime.sleep(1)\n\n# 输入书名\ndriver.find_element_by_id('sword').send_keys(bookname)\n# 检索\ndriver.find_element_by_class_name(\"btn-jiansuo\").click()\n# 检索结果\ndriver.switch_to_frame('book')\ntime.sleep(3)\n\nassert(len(driver.find_elements_by_class_name('yy')) > 1)\n# 确认书名\nassert(driver.find_elements_by_class_name('yy')[0].text\n       == u\"《\" + bookname + u\"》\")\n# 确认有网页阅读\nassert(driver.find_elements_by_class_name('yy')[1].text == u'网页阅读')\n\nbookurl = driver.find_elements_by_class_name('yy')[1].get_attribute('href')\n\ndriver.get(bookurl)\n\n# where img locate\nbase_url = \"http://\" + urllib2.urlparse.urlparse(driver.current_url).netloc\n\nassert(driver.page_source.find(u'超星') >= 0)\n\npages = driver.find_elements_by_xpath('//input[@class=\"Jimg\"]')\n\nfilelist = [e.get_attribute('jpgname') for e in pages]\n\nimglist = {}\n\nfor e in pages:\n    imglist[e.get_attribute('jpgname')] = base_url + e.get_attribute('scr')\n\nfor k, v in imglist.iteritems():\n    if os.path.exists(k):\n        continue\n    try:\n        urllib.urlretrieve(v, k)\n        assert(imghdr.what(k) == 'png')\n    except Exception, e:\n        print e\n\ncmd = u'convert ' + u' '.join(filelist) + ' ' + bookname + u'.pdf'\ncmd = cmd.encode('utf-8')\nos.popen(cmd)\n```\n\n稍微解释下，最后，是用imagemagick把一大堆png格式的书页内容转化成pdf格式。这个过程相当耗内存……如果有空就想想怎么换种方式转pdf，也愿各位看官能指教下。\n\n![](/images/spider/chaoxing7.png)\n\n当然，我并没有把pdf传给任何人，我看完之后跟同学讲了讲，没有做任何盗版行径。同学们也要遵守用户守则，不要乱搞。\n\n让我们引以为戒 [Aaron Swartz](http://zh.wikipedia.org/wiki/%E4%BA%9A%E4%BC%A6%C2%B7%E6%96%AF%E6%B2%83%E8%8C%A8)\n\n![Aaron Swartz](img=http://upload.wikimedia.org/wikipedia/commons/thumb/0/06/Aaron_Swartz_profile.jpg/220px-Aaron_Swartz_profile.jpg)\n\n非法下载书籍的罪名是非常非常严重的！！！！！\n\n---\n\n",metaData:{layout:"post",title:"Python Spider: 超星图书爬取转换",excerpt:"速写爬虫的一些经历",category:"python",tags:["python","spider"],disqus:!0}}}});
{"version":3,"sources":["webpack:///static/js/113.da138b043a14f9093ee9.js","webpack:///./src/posts/2012-10-19-python.md"],"names":["webpackJsonp","239","module","exports","rawContent","metaData","layout","title","excerpt","category","tags","disqus","mathjax"],"mappings":"AAAAA,cAAc,IAAI,MAEZC,IACA,SAASC,EAAQC,GCHvBD,EAAAC,SACAC,WAAA,o5QACAC,UACAC,OAAA,OACAC,MAAA,eACAC,QAAA,GACAC,SAAA,SACAC,MACA,SACA,uBAEAC,QAAA,EACAC,SAAA","file":"static/js/113.da138b043a14f9093ee9.js","sourcesContent":["webpackJsonp([113,170],{\n\n/***/ 239:\n/***/ function(module, exports) {\n\n\tmodule.exports = {\n\t\t\"rawContent\": \"\\n\\n# 优化代码\\n\\n翻译自：[http://scipy-lectures.github.com/advanced/optimizing/index.html](http://scipy-lectures.github.com/advanced/optimizing/index.html)\\n\\n作者:Gaël Varoquaux\\n\\nLicense:Creative Commons Attribution 3.0 United States License (CC-by) http://creativecommons.org/licenses/by/3.0/us\\n\\n> 过早的优化是罪恶的根源。\\n> \\n> ——Donald. Knuth\\n\\n这个章节涉及使Python代码运行更快的策略。\\n\\n**先决条件**\\n\\n\\n- line\\\\_profiler([http://packages.python.org/line_profiler/](http://packages.python.org/line_profiler/))\\n\\n\\n**目录**\\n\\n* toc\\n{: toc}\\n\\n## 优化工作流\\n\\n1. 让它工作：以简单_清晰_的方式书写代码。\\n2. 让它可靠的动作：书写自动化的测试实例，确认你的算法是正确的。如果你中止它，测试将捕捉到中断。\\n3. 优化代码：通过剖析(profile)简单的用例来发现瓶颈，并且加速这些瓶颈，找到更好的算法或实现。记住在剖析一个现实的实例和代码的简洁与执行速度之间权衡。对于有效率的工作，最好让剖析运行约十秒。\\n\\n## 剖析(profile)Python代码\\n\\n**非测量，不优化**\\n\\n- *测量*：剖析(profiling)， 计时(timing)\\n\\n### Timeit\\n\\n在Ipython中，使用`timeit`([http://docs.python.org/library/timeit.html](http://docs.python.org/library/timeit.html))来计算基本运算时间。\\n\\n    In [1]: import numpy as np\\n    \\n    In [2]: a = np.arange(1000)\\n    \\n    In [3]: %timeit a ** 2\\n    100000 loops, best of 3: 3.55 us per loop\\n    \\n    In [4]: %timeit a ** 2.1\\n    10000 loops, best of 3: 105 us per loop\\n    \\n    In [5]: %timeit a * a\\n    100000 loops, best of 3: 3.5 us per loop\\n\\n使用这个指引你的策略选择。\\n\\n**注意：**对于长时间运行的调用，使用`%time`代替`%timeit`;虽然精确度降低但运行更快。\\n\\n### 分析器(Profiler)\\n\\n当你有个很大的程序去分析时会有用，例如以下文件：\\n\\n\\n```python\\nmport numpy as np\\nfrom scipy import linalg\\nfrom sklearn.decomposition import fastica\\n# from mdp import fastica\\n\\ndef test():\\n    data = np.random.random((5000, 100))\\n    u, s, v = linalg.svd(data)\\n    pca = np.dot(u[:10, :], data) \\n    results = fastica(pca.T, whiten=False)\\n\\ntest()\\n```\\n\\n在IPython中我们可以测量脚本运行时间：\\n\\n    In [6]: %run -t demo.py\\n    \\n    IPython CPU timings (estimated):\\n      User   :      11.03 s.\\n      System :       0.43 s.\\n    Wall time:      13.12 s.\\n\\n然后分析(profile)它：\\n\\n    In [7]: %run -p demo.py\\n\\n    1169 function calls in 10.765 seconds\\n    \\n       Ordered by: internal time\\n    \\n       ncalls  tottime  percall  cumtime  percall filename:lineno(function)\\n            2   10.693    5.346   10.699    5.350 decomp_svd.py:14(svd)\\n          144    0.040    0.000    0.040    0.000 {numpy.core.multiarray.dot}\\n            1    0.015    0.015    0.015    0.015 {method 'random_sample' of 'mtrand.RandomState' objects}\\n           20    0.005    0.000    0.007    0.000 function_base.py:526(asarray_chkfinite)\\n            1    0.003    0.003   10.764   10.764 demo.py:1(<module>)\\n           18    0.002    0.000    0.002    0.000 decomp.py:197(eigh)\\n           17    0.001    0.000    0.001    0.000 fastica_.py:219(gprime)\\n           40    0.001    0.000    0.001    0.000 {method 'any' of 'numpy.ndarray' objects}\\n           17    0.001    0.000    0.001    0.000 fastica_.py:215(g)\\n            1    0.001    0.001    0.008    0.008 fastica_.py:88(_ica_par)\\n            1    0.001    0.001   10.764   10.764 {execfile}\\n           52    0.000    0.000    0.001    0.000 twodim_base.py:220(diag)\\n           18    0.000    0.000    0.003    0.000 fastica_.py:40(_sym_decorrelation)\\n           18    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}\\n    \\n显然`svd`(在_decomp.py_中)是占用我们时间最多的东西，即瓶颈。我们得找到一种方法来让这一步运行更快，或者避免这一步(算法优化)。加速代码剩下的部分并无益处。\\n\\n### Line-profiler\\n\\n分析器(profiler)很棒：它告诉我们那个函数费时最多，但并不是它在哪里调用。\\n\\n对此，我们使用[line_profiler](http://packages.python.org/line_profiler/)：在原文件中，我们用`@profile`修饰一些我们想要检查的函数(不用导入它)：\\n\\n\\n```python\\n@profile\\ndef test():\\n    data = np.random.random((5000, 100))\\n    u, s, v = linalg.svd(data)\\n    pca = np.dot(u[:10, :], data)\\n    results = fastica(pca.T, whiten=False)\\n```\\n\\n然后我们使用[kernprof.py](packages.python.org/line_profiler/kernprof.py)程序，用-l和-v：\\n\\n    lyy@arch ~ % kernprof.py -l -v demo.py\\n    Wrote profile results to demo.py.lprof\\n    Timer unit: 1e-06 s\\n    \\n    File: demo.py\\n    Function: test at line 6\\n    Total time: 10.5932 s\\n    \\n    Line #      Hits         Time  Per Hit   % Time  Line Contents\\n    ==============================================================\\n         6                                           @profile\\n         7                                           def test():\\n         8         1        11070  11070.0      0.1          data = np.random.random((5000, 100))\\n         9         1     10530291 10530291.0     99.4          u, s, v = linalg.svd(data)\\n        10         1        31026  31026.0      0.3          pca = np.dot(u[:10, :], data)\\n        11         1        20766  20766.0      0.2          results = fastica(pca.T)\\n    \\n    kernprof.py -l -v demo.py  12.57s user 0.25s system 99% cpu 12.891 total\\n    \\n_SVD占用了大部分时间_。我们需要优化这行。\\n\\n## 让代码更快\\n\\n一旦我们确认了瓶颈，我们需要让相应的代码运行更快。\\n\\n### 算法优化\\n\\n首先寻找算法优化：有没有运算更少或更好的方式？\\n\\n对于更高层次地看待问题，充分理解算法后的数学很有帮助。然而，寻找简单的改变并不寻常，像_移动计算[^1]和在循环外分配内存[^2]_,会带来很大益处。\\n\\n####SVD的示例\\n\\n在以上每个例子中，SVD——[奇异值分解](http://en.wikipedia.org/wiki/Singular_value_decomposition)——是占用时间最多的。确实，当输入矩阵大小为n时算法计算代价大约是$n^3$。\\n\\n然而，这些例子中，我们都没有使用SVD的输出，但是仅仅使用它最开始返回的参数最初很少的几行。如果我们使用scipy的`svd`实现，我们可以获得一个不完整的SVD版本。注意这个在scipy中的线性代数实现比numpy中的更加丰富，应该优先使用。\\n\\n    In [4]: %timeit np.linalg.svd(data)\\n    1 loops, best of 3: 10.8 s per loop\\n    \\n    In [5]: from scipy import linalg\\n    \\n    In [6]: %timeit linalg.svd(data)\\n    1 loops, best of 3: 10.4 s per loop\\n    \\n    In [7]: %timeit linalg.svd(data, full_matrices=False)\\n    1 loops, best of 3: 278 ms per loop\\n    \\n    In [8]: %timeit np.linalg.svd(data, full_matrices=False)\\n    1 loops, best of 3: 276 ms per loop\\n\\n真正的不完全SVD，例如仅仅计算前十个特征向量，可以用arpack[^3]计算，可以在`scipy.sparse.linalg.eigsh`获得。\\n\\n**计算线性代数**\\n\\n对于确定的算法，许多瓶颈将是线性代数计算。在本例中，使用正确的函数解决正确的问题是关键。例如，一个对称矩阵的本征值问题比一个普通矩阵更容易解决。同样的，很多时候，你可以避免反转矩阵，并且使用代价更小(并更数值稳定)的运算。\\n\\n了解你的线性代数计算。当有疑问时，探索scipy.linalg，并且用%timeit 来对你的数据尝试不同的选择。\\n\\n## 写更快的数值代码\\n\\n一个完整的关于使用numpy的讨论可以在[Advanced Numpy](http://scipy-lectures.github.com/advanced/advanced_numpy/index.html#advanced-numpy)章节中找到，或者在van der Walt等人的文章[The NumPy array: a structure for efficient numerical computation](http://hal.inria.fr/inria-00564007/en)中。这里我们仅仅讨论加速代码运行速度常见的技巧。\\n\\n- 向量化循环\\n  \\n  找到技巧来避免使用numpy数组循环。对此，掩码(masks)数组和索引(indices)数组会更有用。\\n\\n- 广播\\n\\n  使用[广播(broadcasting)](http://scipy-lectures.github.com/intro/numpy/operations.html#broadcasting)来在结合它们之前对数组尽可能少的运算。\\n\\n- 在适当的位置运算\\n\\n      In [9]: a = np.zeros(1e7)\\n      In [11]: %timeit global a ; a *= 0\\n      10 loops, best of 3: 29.1 ms per loop\\n      \\n      in [12]: %timeit global a ; a = 0*a\\n      10 loops, best of 3: 54.3 ms per loop\\n \\n   **注意：**我们需要个`global a`让timeit工作，因为它被赋给a，因此将它视作一个局部变量。\\n\\n- 善待内存：使用视图(views)而非拷贝(copies)\\n\\n  拷贝一个大数组就像对它们进行简单的数值计算一样耗费资源\\n    \\n      In [18]: a = np.zeros(1e7)\\n      \\n      In [19]: %timeit a.copy()\\n      10 loops, best of 3: 69 ms per loop\\n      \\n      In [20]: %timeit a + 1\\n      10 loops, best of 3: 56.2 ms per loop\\n\\n- 小心缓存影响(cache effects)\\n\\n  内存存取当是成组时是省资源的：以连续的方式存取一个大数组比随机存取更快。这意味着除其它事项外更小的元素间距更快(参见[CPU cache effects](http://scipy-lectures.github.com/advanced/advanced_numpy/index.html#cache-effects))[^4]\\n\\n    In [21]: c = np.zeros((1e4, 1e4), order='C')\\n    \\n      In [22]: %timeit c.sum(axis=0)\\n      1 loops, best of 3: 3.62 s per loop\\n      \\n      In [23]: %timeit c.sum(axis=1)\\n      10 loops, best of 3: 171 ms per loop\\n      \\n      In [24]: c.strides\\n      Out[24]: (80000, 8)\\n\\n      In [25]: c = np.zeros((1e4, 1e4), order='F')\\n      \\n      In [26]: %timeit c.sum(axis=0)\\n      1 loops, best of 3: 166 ms per loop\\n      \\n      In [27]: %timeit c.sum(axis=1)\\n      1 loops, best of 3: 3.63 s per loop\\n\\n  这就是为何Fortran顺序或C顺序可能对运算的影响很大：\\n\\n      in [28]: a = np.random.rand(20, 2**18)\\n      \\n      in [29]: b = np.random.rand(20, 2**18)\\n      \\n      in [30]: %timeit np.dot(b, a.T)\\n      1 loops, best of 3: 278 ms per loop\\n      \\n      in [31]: c = np.ascontiguousarray(a.T)\\n      \\n      in [32]: %timeit np.dot(b, c)\\n      1 loops, best of 3: 1.94 s per loop\\n\\n\\n  注意拷贝数据来解决这个影响不值得：\\n\\n      In [34]: %timeit c = np.ascontiguousarray(a.T)\\n      10 loops, best of 3: 45.4 ms per loop\\n\\n  使用numexpr来自动为这种效应优化会很有用。\\n\\n- 使用编译好的代码\\n\\n  一旦你确定所有高层次的优化都已经摸索过了，最后手段是将热点，也就是耗费时间最多的代码或函数，变成编译好的代码。对于编译代码，最优的选择是使用[Cython](http://www.cython.org/):它很轻松地让你将已知的Python代码转换成编译好的代码，并且对numpy数组很好利用[numpy支持](http://docs.cython.org/src/tutorial/numpy.html)产生有效率的代码，例如通过循环展开(unrolling loops)。\\n  \\n**Waring:**对上述所有流程，分析(profile)并且计时(time)你的选择。不要以理论为依据来进行优化。\\n{: alert }\\n\\n\\n[^1]:存疑\\n[^2]:我不懂\\n[^3]:[Arpack——fortran数值计算库](http://en.wikipedia.org/wiki/ARPACK)\\n[^4]:python科学计算里numpy部分讲得非常清楚，第二种间距小的明显快了很多。\\n\",\n\t\t\"metaData\": {\n\t\t\t\"layout\": \"post\",\n\t\t\t\"title\": \"优化代码(Python)\",\n\t\t\t\"excerpt\": \"\",\n\t\t\t\"category\": \"python\",\n\t\t\t\"tags\": [\n\t\t\t\t\"python\",\n\t\t\t\t\"scipy-lecture-notes\"\n\t\t\t],\n\t\t\t\"disqus\": true,\n\t\t\t\"mathjax\": true\n\t\t}\n\t};\n\n/***/ }\n\n});\n\n\n/** WEBPACK FOOTER **\n ** static/js/113.da138b043a14f9093ee9.js\n **/","module.exports = {\n\t\"rawContent\": \"\\n\\n# 优化代码\\n\\n翻译自：[http://scipy-lectures.github.com/advanced/optimizing/index.html](http://scipy-lectures.github.com/advanced/optimizing/index.html)\\n\\n作者:Gaël Varoquaux\\n\\nLicense:Creative Commons Attribution 3.0 United States License (CC-by) http://creativecommons.org/licenses/by/3.0/us\\n\\n> 过早的优化是罪恶的根源。\\n> \\n> ——Donald. Knuth\\n\\n这个章节涉及使Python代码运行更快的策略。\\n\\n**先决条件**\\n\\n\\n- line\\\\_profiler([http://packages.python.org/line_profiler/](http://packages.python.org/line_profiler/))\\n\\n\\n**目录**\\n\\n* toc\\n{: toc}\\n\\n## 优化工作流\\n\\n1. 让它工作：以简单_清晰_的方式书写代码。\\n2. 让它可靠的动作：书写自动化的测试实例，确认你的算法是正确的。如果你中止它，测试将捕捉到中断。\\n3. 优化代码：通过剖析(profile)简单的用例来发现瓶颈，并且加速这些瓶颈，找到更好的算法或实现。记住在剖析一个现实的实例和代码的简洁与执行速度之间权衡。对于有效率的工作，最好让剖析运行约十秒。\\n\\n## 剖析(profile)Python代码\\n\\n**非测量，不优化**\\n\\n- *测量*：剖析(profiling)， 计时(timing)\\n\\n### Timeit\\n\\n在Ipython中，使用`timeit`([http://docs.python.org/library/timeit.html](http://docs.python.org/library/timeit.html))来计算基本运算时间。\\n\\n    In [1]: import numpy as np\\n    \\n    In [2]: a = np.arange(1000)\\n    \\n    In [3]: %timeit a ** 2\\n    100000 loops, best of 3: 3.55 us per loop\\n    \\n    In [4]: %timeit a ** 2.1\\n    10000 loops, best of 3: 105 us per loop\\n    \\n    In [5]: %timeit a * a\\n    100000 loops, best of 3: 3.5 us per loop\\n\\n使用这个指引你的策略选择。\\n\\n**注意：**对于长时间运行的调用，使用`%time`代替`%timeit`;虽然精确度降低但运行更快。\\n\\n### 分析器(Profiler)\\n\\n当你有个很大的程序去分析时会有用，例如以下文件：\\n\\n\\n```python\\nmport numpy as np\\nfrom scipy import linalg\\nfrom sklearn.decomposition import fastica\\n# from mdp import fastica\\n\\ndef test():\\n    data = np.random.random((5000, 100))\\n    u, s, v = linalg.svd(data)\\n    pca = np.dot(u[:10, :], data) \\n    results = fastica(pca.T, whiten=False)\\n\\ntest()\\n```\\n\\n在IPython中我们可以测量脚本运行时间：\\n\\n    In [6]: %run -t demo.py\\n    \\n    IPython CPU timings (estimated):\\n      User   :      11.03 s.\\n      System :       0.43 s.\\n    Wall time:      13.12 s.\\n\\n然后分析(profile)它：\\n\\n    In [7]: %run -p demo.py\\n\\n    1169 function calls in 10.765 seconds\\n    \\n       Ordered by: internal time\\n    \\n       ncalls  tottime  percall  cumtime  percall filename:lineno(function)\\n            2   10.693    5.346   10.699    5.350 decomp_svd.py:14(svd)\\n          144    0.040    0.000    0.040    0.000 {numpy.core.multiarray.dot}\\n            1    0.015    0.015    0.015    0.015 {method 'random_sample' of 'mtrand.RandomState' objects}\\n           20    0.005    0.000    0.007    0.000 function_base.py:526(asarray_chkfinite)\\n            1    0.003    0.003   10.764   10.764 demo.py:1(<module>)\\n           18    0.002    0.000    0.002    0.000 decomp.py:197(eigh)\\n           17    0.001    0.000    0.001    0.000 fastica_.py:219(gprime)\\n           40    0.001    0.000    0.001    0.000 {method 'any' of 'numpy.ndarray' objects}\\n           17    0.001    0.000    0.001    0.000 fastica_.py:215(g)\\n            1    0.001    0.001    0.008    0.008 fastica_.py:88(_ica_par)\\n            1    0.001    0.001   10.764   10.764 {execfile}\\n           52    0.000    0.000    0.001    0.000 twodim_base.py:220(diag)\\n           18    0.000    0.000    0.003    0.000 fastica_.py:40(_sym_decorrelation)\\n           18    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}\\n    \\n显然`svd`(在_decomp.py_中)是占用我们时间最多的东西，即瓶颈。我们得找到一种方法来让这一步运行更快，或者避免这一步(算法优化)。加速代码剩下的部分并无益处。\\n\\n### Line-profiler\\n\\n分析器(profiler)很棒：它告诉我们那个函数费时最多，但并不是它在哪里调用。\\n\\n对此，我们使用[line_profiler](http://packages.python.org/line_profiler/)：在原文件中，我们用`@profile`修饰一些我们想要检查的函数(不用导入它)：\\n\\n\\n```python\\n@profile\\ndef test():\\n    data = np.random.random((5000, 100))\\n    u, s, v = linalg.svd(data)\\n    pca = np.dot(u[:10, :], data)\\n    results = fastica(pca.T, whiten=False)\\n```\\n\\n然后我们使用[kernprof.py](packages.python.org/line_profiler/kernprof.py)程序，用-l和-v：\\n\\n    lyy@arch ~ % kernprof.py -l -v demo.py\\n    Wrote profile results to demo.py.lprof\\n    Timer unit: 1e-06 s\\n    \\n    File: demo.py\\n    Function: test at line 6\\n    Total time: 10.5932 s\\n    \\n    Line #      Hits         Time  Per Hit   % Time  Line Contents\\n    ==============================================================\\n         6                                           @profile\\n         7                                           def test():\\n         8         1        11070  11070.0      0.1          data = np.random.random((5000, 100))\\n         9         1     10530291 10530291.0     99.4          u, s, v = linalg.svd(data)\\n        10         1        31026  31026.0      0.3          pca = np.dot(u[:10, :], data)\\n        11         1        20766  20766.0      0.2          results = fastica(pca.T)\\n    \\n    kernprof.py -l -v demo.py  12.57s user 0.25s system 99% cpu 12.891 total\\n    \\n_SVD占用了大部分时间_。我们需要优化这行。\\n\\n## 让代码更快\\n\\n一旦我们确认了瓶颈，我们需要让相应的代码运行更快。\\n\\n### 算法优化\\n\\n首先寻找算法优化：有没有运算更少或更好的方式？\\n\\n对于更高层次地看待问题，充分理解算法后的数学很有帮助。然而，寻找简单的改变并不寻常，像_移动计算[^1]和在循环外分配内存[^2]_,会带来很大益处。\\n\\n####SVD的示例\\n\\n在以上每个例子中，SVD——[奇异值分解](http://en.wikipedia.org/wiki/Singular_value_decomposition)——是占用时间最多的。确实，当输入矩阵大小为n时算法计算代价大约是$n^3$。\\n\\n然而，这些例子中，我们都没有使用SVD的输出，但是仅仅使用它最开始返回的参数最初很少的几行。如果我们使用scipy的`svd`实现，我们可以获得一个不完整的SVD版本。注意这个在scipy中的线性代数实现比numpy中的更加丰富，应该优先使用。\\n\\n    In [4]: %timeit np.linalg.svd(data)\\n    1 loops, best of 3: 10.8 s per loop\\n    \\n    In [5]: from scipy import linalg\\n    \\n    In [6]: %timeit linalg.svd(data)\\n    1 loops, best of 3: 10.4 s per loop\\n    \\n    In [7]: %timeit linalg.svd(data, full_matrices=False)\\n    1 loops, best of 3: 278 ms per loop\\n    \\n    In [8]: %timeit np.linalg.svd(data, full_matrices=False)\\n    1 loops, best of 3: 276 ms per loop\\n\\n真正的不完全SVD，例如仅仅计算前十个特征向量，可以用arpack[^3]计算，可以在`scipy.sparse.linalg.eigsh`获得。\\n\\n**计算线性代数**\\n\\n对于确定的算法，许多瓶颈将是线性代数计算。在本例中，使用正确的函数解决正确的问题是关键。例如，一个对称矩阵的本征值问题比一个普通矩阵更容易解决。同样的，很多时候，你可以避免反转矩阵，并且使用代价更小(并更数值稳定)的运算。\\n\\n了解你的线性代数计算。当有疑问时，探索scipy.linalg，并且用%timeit 来对你的数据尝试不同的选择。\\n\\n## 写更快的数值代码\\n\\n一个完整的关于使用numpy的讨论可以在[Advanced Numpy](http://scipy-lectures.github.com/advanced/advanced_numpy/index.html#advanced-numpy)章节中找到，或者在van der Walt等人的文章[The NumPy array: a structure for efficient numerical computation](http://hal.inria.fr/inria-00564007/en)中。这里我们仅仅讨论加速代码运行速度常见的技巧。\\n\\n- 向量化循环\\n  \\n  找到技巧来避免使用numpy数组循环。对此，掩码(masks)数组和索引(indices)数组会更有用。\\n\\n- 广播\\n\\n  使用[广播(broadcasting)](http://scipy-lectures.github.com/intro/numpy/operations.html#broadcasting)来在结合它们之前对数组尽可能少的运算。\\n\\n- 在适当的位置运算\\n\\n      In [9]: a = np.zeros(1e7)\\n      In [11]: %timeit global a ; a *= 0\\n      10 loops, best of 3: 29.1 ms per loop\\n      \\n      in [12]: %timeit global a ; a = 0*a\\n      10 loops, best of 3: 54.3 ms per loop\\n \\n   **注意：**我们需要个`global a`让timeit工作，因为它被赋给a，因此将它视作一个局部变量。\\n\\n- 善待内存：使用视图(views)而非拷贝(copies)\\n\\n  拷贝一个大数组就像对它们进行简单的数值计算一样耗费资源\\n    \\n      In [18]: a = np.zeros(1e7)\\n      \\n      In [19]: %timeit a.copy()\\n      10 loops, best of 3: 69 ms per loop\\n      \\n      In [20]: %timeit a + 1\\n      10 loops, best of 3: 56.2 ms per loop\\n\\n- 小心缓存影响(cache effects)\\n\\n  内存存取当是成组时是省资源的：以连续的方式存取一个大数组比随机存取更快。这意味着除其它事项外更小的元素间距更快(参见[CPU cache effects](http://scipy-lectures.github.com/advanced/advanced_numpy/index.html#cache-effects))[^4]\\n\\n    In [21]: c = np.zeros((1e4, 1e4), order='C')\\n    \\n      In [22]: %timeit c.sum(axis=0)\\n      1 loops, best of 3: 3.62 s per loop\\n      \\n      In [23]: %timeit c.sum(axis=1)\\n      10 loops, best of 3: 171 ms per loop\\n      \\n      In [24]: c.strides\\n      Out[24]: (80000, 8)\\n\\n      In [25]: c = np.zeros((1e4, 1e4), order='F')\\n      \\n      In [26]: %timeit c.sum(axis=0)\\n      1 loops, best of 3: 166 ms per loop\\n      \\n      In [27]: %timeit c.sum(axis=1)\\n      1 loops, best of 3: 3.63 s per loop\\n\\n  这就是为何Fortran顺序或C顺序可能对运算的影响很大：\\n\\n      in [28]: a = np.random.rand(20, 2**18)\\n      \\n      in [29]: b = np.random.rand(20, 2**18)\\n      \\n      in [30]: %timeit np.dot(b, a.T)\\n      1 loops, best of 3: 278 ms per loop\\n      \\n      in [31]: c = np.ascontiguousarray(a.T)\\n      \\n      in [32]: %timeit np.dot(b, c)\\n      1 loops, best of 3: 1.94 s per loop\\n\\n\\n  注意拷贝数据来解决这个影响不值得：\\n\\n      In [34]: %timeit c = np.ascontiguousarray(a.T)\\n      10 loops, best of 3: 45.4 ms per loop\\n\\n  使用numexpr来自动为这种效应优化会很有用。\\n\\n- 使用编译好的代码\\n\\n  一旦你确定所有高层次的优化都已经摸索过了，最后手段是将热点，也就是耗费时间最多的代码或函数，变成编译好的代码。对于编译代码，最优的选择是使用[Cython](http://www.cython.org/):它很轻松地让你将已知的Python代码转换成编译好的代码，并且对numpy数组很好利用[numpy支持](http://docs.cython.org/src/tutorial/numpy.html)产生有效率的代码，例如通过循环展开(unrolling loops)。\\n  \\n**Waring:**对上述所有流程，分析(profile)并且计时(time)你的选择。不要以理论为依据来进行优化。\\n{: alert }\\n\\n\\n[^1]:存疑\\n[^2]:我不懂\\n[^3]:[Arpack——fortran数值计算库](http://en.wikipedia.org/wiki/ARPACK)\\n[^4]:python科学计算里numpy部分讲得非常清楚，第二种间距小的明显快了很多。\\n\",\n\t\"metaData\": {\n\t\t\"layout\": \"post\",\n\t\t\"title\": \"优化代码(Python)\",\n\t\t\"excerpt\": \"\",\n\t\t\"category\": \"python\",\n\t\t\"tags\": [\n\t\t\t\"python\",\n\t\t\t\"scipy-lecture-notes\"\n\t\t],\n\t\t\"disqus\": true,\n\t\t\"mathjax\": true\n\t}\n};\n\n\n/*****************\n ** WEBPACK FOOTER\n ** ./~/.npminstall/json-loader/0.5.4/json-loader!./loader/post-loader.js!./src/posts/2012-10-19-python.md\n ** module id = 239\n ** module chunks = 113\n **/"],"sourceRoot":""}